{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 2:\n",
        "  - The client wants to have a ML model so that we can use it to test their HIP software.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/cats_vs_dogs_dataset/train\n",
        "* inputs/cats_vs_dogs_dataset/validation\n",
        "* inputs/cats_vs_dogs_dataset/test\n",
        "* image shape embeddings\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Images distribution plot in train, validation, and test set.\n",
        "* Image augmentation\n",
        "* Machine learning model creation and training.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Preparation setup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r /workspace/pp5-cats-vs-dogs/requirements.txt 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set working directory to root project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "root_dir = os.getcwd()\n",
        "print('New folder: ' + root_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set input directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset_folder = 'inputs/cats_vs_dogs_dataset_small'\n",
        "train_path = dataset_folder + '/train'\n",
        "validation_path = dataset_folder + '/validation'\n",
        "test_path = dataset_folder + '/test'\n",
        "train_path"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v9'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(root_dir) and version in os.listdir(root_dir + '/outputs'):\n",
        "    print(f'Version {version} is already available.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)\n",
        "    print(f'New directory for version {version} has been created')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set label names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "print('Label for the images are', labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v9'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Number of images in dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame(columns=['Set', 'Label', 'Frequency'])\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        new_row = pd.DataFrame({\n",
        "            'Set': [folder],\n",
        "            'Label': [label],\n",
        "            'Frequency': [len(os.listdir(dataset_folder + '/' + folder + '/' + label))]\n",
        "        })\n",
        "        df_freq = pd.concat([df_freq, new_row], ignore_index=True)\n",
        "\n",
        "        print(\n",
        "            f\"* {folder} - {label}: {len(os.listdir(dataset_folder +'/'+ folder + '/' + label))} images\")\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Image data augmentation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Initialize image data generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "augmented_image_data = ImageDataGenerator(rotation_range=20,\n",
        "                                          width_shift_range=0.10,\n",
        "                                          height_shift_range=0.10,\n",
        "                                          shear_range=0.1,\n",
        "                                          zoom_range=0.1,\n",
        "                                          horizontal_flip=True,\n",
        "                                          vertical_flip=True,\n",
        "                                          fill_mode='nearest',\n",
        "                                          rescale=1./255\n",
        "                                          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Augment training, validation and test image datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_set = augmented_image_data.flow_from_directory(train_path,\n",
        "                                                     target_size=image_shape[:2],\n",
        "                                                     color_mode='rgb',\n",
        "                                                     batch_size=batch_size,\n",
        "                                                     class_mode='categorical',\n",
        "                                                     shuffle=True\n",
        "                                                     )\n",
        "\n",
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(validation_path,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        color_mode='rgb',\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False\n",
        "                                                                        )\n",
        "\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  color_mode='rgb',\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False\n",
        "                                                                  )\n",
        "\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = train_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot augmented validation and test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = validation_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for _ in range(3):\n",
        "    img, label = test_set.next()\n",
        "    print(img.shape)\n",
        "    plt.imshow(img[0])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save class indicies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# **Model creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## ML model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, BatchNormalization\n",
        "\n",
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(Conv2D(filters=16, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3),\n",
        "              input_shape=image_shape, activation='relu', ))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "\n",
        "    model.add(Dropout(0.5))\n",
        "    model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_tf_model().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Fit model for training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=len(train_set.classes) // batch_size,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop],\n",
        "          verbose=1\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save(f'{file_path}/cats_vs_dogs_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Model performance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model learning curve"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Model evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from keras.models import load_model\n",
        "model = load_model(f'{file_path}/cats_vs_dogs_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evaluate on the test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "evaluation = model.evaluate(test_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Save evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=evaluation,\n",
        "            filename=f'{file_path}/evaluation.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Predict on new data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Load random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[0]\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Convert image to array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Predict class on the image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba > 0.5]\n",
        "\n",
        "if pred_class == target_map[0]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(pred_proba)\n",
        "print(pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check changed files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git status"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Add, commit and push to repo (all files or individual file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!git add .\n",
        "\n",
        "!git commit -m \"Message\"\n",
        "\n",
        "!git push"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions\n",
        "\n",
        "Model v1\n",
        "- 0,7986 acc, 62 min to fit\n",
        "- Conv2D -> filters= 32 -> 64 -> 64 = 16,9 mil params\n",
        "- Modelsize 388 mb - deleted\n",
        "\n",
        "New v1\n",
        "- 0,9223 acc, 19 min to fit\n",
        "- Conv2D -> filters= 16 -> 32 -> 32 = 8,4 mil params\n",
        "- Modelsize 97 mb - saved and pushed to github\n",
        "\n",
        "**Nr of params affect modelsize.**\n",
        "\n",
        "New v1 with evaluation\n",
        "- 0.8254, 43 min to fit (slow gitpod workspace)\n",
        "- Conv2D -> filters= 16 -> 32 -> 32 = 8,4 mil params\n",
        "- Modelsize 97 mb - saved and pushed to github\n",
        "\n",
        "\n",
        "V2 \n",
        "- Used softmax instead of sigmoid\n",
        "- loss: 1.0727 - accuracy: 0.6230 on test set\n",
        "- 16 min to train\n",
        "\n",
        "V3\n",
        "- Reduced image size to 25% of average\n",
        "- loss: 0.7066 - accuracy: 0.5120\n",
        "- 22 seconds to train\n",
        "\n",
        "New V3\n",
        "- reduced image size to 50% of average\n",
        "- loss: 0.6775 - accuracy: 0.6520\n",
        "- 3 min 25 sec to train\n",
        "- modelsize = 22 mb\n",
        "\n",
        "V4\n",
        "- Add image augmentation\n",
        "- loss: 0.5591 - accuracy: 0.7220\n",
        "- 5 min to train\n",
        "- modelsize = 22mb\n",
        "\n",
        "V5\n",
        "- Increase to 25 epochs\n",
        "- Use all 25000 dataset images\n",
        "- Reduced image size to 25% of average\n",
        "- loss: 0.3806 - accuracy: 0.8318\n",
        "- 24 min to train \n",
        "- modelsize = 4 MB\n",
        "\n",
        "V6\n",
        "- use smaller 5000 img dataset\n",
        "- Reduced image size to 33% of average\n",
        "- loss: 0.5637 - accuracy: 0.7000\n",
        "- 5 min to train, ended on 18 epochs\n",
        "- modelsize = 9MB\n",
        "\n",
        "V7\n",
        "- Reduced image size to 25% of average\n",
        "- more filters used\n",
        "- loss: 0.5631 - accuracy: 0.7050\n",
        "- 4.5 min to train\n",
        "\n",
        "Hypertuning\n",
        "increase dropout layer\n",
        "- loss: 0.5122 - accuracy: 0.7550\n",
        "\n",
        "Increase kernels\n",
        "- loss: 0.6885 - accuracy: 0.5560\n",
        "\n",
        "Increase filters\n",
        "- loss: 0.5123 - accuracy: 0.7540\n",
        "\n",
        "Add another dense layer\n",
        "- loss: 0.6011 - accuracy: 0.6990\n",
        "\n",
        "Change filters from high to low\n",
        "- loss: 0.6747 - accuracy: 0.5770\n",
        "\n",
        "Remove a convo layer\n",
        "- loss: 0.6030 - accuracy: 0.6790\n",
        "\n",
        "Increase dense layer and decrease convo filters\n",
        "- loss: 0.4961 - accuracy: 0.7630\n",
        "\n",
        "Adam learning rate 0.0001\n",
        "- loss: 0.5734 - accuracy: 0.6960\n",
        "\n",
        "Adam learning rate 0.01\n",
        "- loss: 0.6932 - accuracy: 0.5000\n",
        "\n",
        "Adam learning rate 0.001\n",
        "- loss: 0.6038 - accuracy: 0.6910\n",
        "\n",
        "Batch size 10\n",
        "- loss: 0.5968 - accuracy: 0.6890\n",
        "\n",
        "Batch size 50\n",
        "- 0.5296 - accuracy: 0.7350\n",
        "\n",
        "Add Batchnormalization layers\n",
        "- loss: 0.5476 - accuracy: 0.7260\n",
        "\n",
        "Batch size 20\n",
        "- loss: 0.6496 - accuracy: 0.6550\n",
        "\n",
        "Double image size (batch 50)\n",
        "- loss: 0.5691 - accuracy: 0.6830\n",
        "\n",
        "V8\n",
        "Img shape 33% of avg\n",
        "Full dataset of 25000 images\n",
        "- - loss: 0.4194 - accuracy: 0.8246\n",
        "\n",
        "V9 - to be trained and tested\n",
        "New hypothesis - It is better for performance to use bigger image shape than bigger dataset.\n",
        "Validate: Using smaller dataset (5000 images) and the bigger average image size.\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
