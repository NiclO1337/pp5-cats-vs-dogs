{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch images from Kaggle and split into train, test and validation folders\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: inputs/datasets/cats_vs_dogs_dataset\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* Must delete unlabelled images from the Kaggle dataset as they can not be used for this project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install requirements, import libraries, and set variable DatasetFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install -r /workspace/pp5-cats-vs-dogs/requirements.txt 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "DatasetFolder = 'inputs/cats_vs_dogs_dataset_small'\n",
        "DatasetFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change working directory to root project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# **Download dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Install Kaggle, configure the directory, and set permissions for the Kaggle authentication JSON.\n",
        "* Download the Kaggle dataset.\n",
        "* Unzip the file and delete the zip file and unlabeled images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.5.12 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json\n",
        "print('Directory configured and permissions set.')\n",
        "\n",
        "! kaggle competitions download -c dogs-vs-cats -p {DatasetFolder}\n",
        "\n",
        "print('Extracting files...')\n",
        "with zipfile.ZipFile(DatasetFolder + '/dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DatasetFolder)    \n",
        "\n",
        "with zipfile.ZipFile(DatasetFolder + '/train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DatasetFolder)\n",
        "\n",
        "os.remove(DatasetFolder + '/dogs-vs-cats.zip')\n",
        "os.remove(DatasetFolder + '/test1.zip')\n",
        "os.remove(DatasetFolder + '/train.zip')\n",
        "os.remove(DatasetFolder + '/sampleSubmission.csv')\n",
        "print('Unused files deleted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# **Data Preparation and cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check and remove non-image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  # remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))\n",
        "\n",
        "\n",
        "remove_non_image_file(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete 80% of image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_dir = os.path.join(DatasetFolder, 'train')\n",
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delete_80_percent_of_files(train_dir):\n",
        "    file_list = os.listdir(train_dir)\n",
        "    num_files_to_delete = int(0.8 * len(file_list))\n",
        "    files_to_delete = random.sample(file_list, num_files_to_delete)\n",
        "    for file_name in files_to_delete:\n",
        "        file_path = os.path.join(train_dir, file_name)\n",
        "        os.remove(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "delete_80_percent_of_files(train_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split into different folders for cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_images(my_data_dir):\n",
        "    # Define the source and target directories\n",
        "    source_dir = os.path.join(my_data_dir, 'train')\n",
        "    cat_dir = os.path.join(my_data_dir, 'cat')\n",
        "    dog_dir = os.path.join(my_data_dir, 'dog')\n",
        "    \n",
        "    # Create 'cat' and 'dog' directories if they don't exist\n",
        "    for dir_name in [cat_dir, dog_dir]:\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "    \n",
        "    # Iterate through all files in the 'train' folder\n",
        "    for file_name in os.listdir(source_dir):\n",
        "        file_path = os.path.join(source_dir, file_name)\n",
        "        \n",
        "        # Check if the filename contains 'cat' or 'dog'\n",
        "        if 'cat' in file_name.lower():\n",
        "            target_dir = cat_dir\n",
        "        elif 'dog' in file_name.lower():\n",
        "            target_dir = dog_dir\n",
        "        else:\n",
        "            continue  # Skip files without labels\n",
        "        \n",
        "        # Move the file to the corresponding folder\n",
        "        shutil.move(file_path, target_dir)\n",
        "    \n",
        "    # Delete the 'train' folder after moving all files\n",
        "    shutil.rmtree(source_dir)\n",
        "\n",
        "\n",
        "split_images(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split dataset into train (70%), validation (10%) and test (20%) sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # gets classes labels\n",
        "    labels = os.listdir(my_data_dir)  # it should get only the folder names\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        # create train, test folders with classes labels sub-folder\n",
        "        for folder in ['train', 'validation', 'test']:\n",
        "            for label in labels:\n",
        "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
        "\n",
        "        for label in labels:\n",
        "\n",
        "            files = os.listdir(my_data_dir + '/' + label)\n",
        "            random.shuffle(files)\n",
        "\n",
        "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "            count = 1\n",
        "            for file_name in files:\n",
        "                if count <= train_set_files_qty:\n",
        "                    # move a given file to the train set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
        "\n",
        "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                    # move a given file to the validation set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "                else:\n",
        "                    # move given file to test set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
        "\n",
        "                count += 1\n",
        "\n",
        "            os.rmdir(my_data_dir + '/' + label)\n",
        "\n",
        "\n",
        "split_train_validation_test_images(my_data_dir=DatasetFolder,\n",
        "                                   train_set_ratio=0.7,\n",
        "                                   validation_set_ratio=0.1,\n",
        "                                   test_set_ratio=0.2\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset has been downloaded and images prepared for analysis. <br>\n",
        "Proceed to next notebook for Data visualization or Modelling and evaluation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
