{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch images from Kaggle and split into train, test and validation folders\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: inputs/datasets/cats_vs_dogs_dataset\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* Must delete unlabelled images from the Kaggle dataset as they can not be used for this project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install requirements, import libraries, and set variable DatasetFolder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirements installed.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r /workspace/pp5-cats-vs-dogs/requirements.txt 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'inputs/cats_vs_dogs_dataset_small'"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy\n",
        "import zipfile\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "DatasetFolder = 'inputs/cats_vs_dogs_dataset_small'\n",
        "DatasetFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change working directory to root project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current folder: /workspace/pp5-cats-vs-dogs/jupyter_notebooks\n",
            "New folder: /workspace/pp5-cats-vs-dogs\n"
          ]
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# **Download dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Install Kaggle, configure the directory, and set permissions for the Kaggle authentication JSON.\n",
        "* Download the Kaggle dataset.\n",
        "* Unzip the file and delete the zip file and unlabeled images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.5.12 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json\n",
        "print('Directory configured and permissions set.')\n",
        "\n",
        "! kaggle competitions download -c dogs-vs-cats -p {DatasetFolder}\n",
        "\n",
        "print('Extracting files...')\n",
        "with zipfile.ZipFile(DatasetFolder + '/dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DatasetFolder)\n",
        "\n",
        "with zipfile.ZipFile(DatasetFolder + '/train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DatasetFolder)\n",
        "\n",
        "os.remove(DatasetFolder + '/dogs-vs-cats.zip')\n",
        "os.remove(DatasetFolder + '/test1.zip')\n",
        "os.remove(DatasetFolder + '/train.zip')\n",
        "os.remove(DatasetFolder + '/sampleSubmission.csv')\n",
        "print('Unused files deleted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# **Data Preparation and cleaning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Check and remove non-image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  # remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))\n",
        "\n",
        "\n",
        "remove_non_image_file(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split into different folders for cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_images(my_data_dir):\n",
        "    # Define the source and target directories\n",
        "    source_dir = os.path.join(my_data_dir, 'train')\n",
        "    cat_dir = os.path.join(my_data_dir, 'cat')\n",
        "    dog_dir = os.path.join(my_data_dir, 'dog')\n",
        "\n",
        "    # Create 'cat' and 'dog' directories if they don't exist\n",
        "    for dir_name in [cat_dir, dog_dir]:\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "\n",
        "    # Iterate through all files in the 'train' folder\n",
        "    for file_name in os.listdir(source_dir):\n",
        "        file_path = os.path.join(source_dir, file_name)\n",
        "\n",
        "        # Check if the filename contains 'cat' or 'dog'\n",
        "        if 'cat' in file_name.lower():\n",
        "            target_dir = cat_dir\n",
        "        elif 'dog' in file_name.lower():\n",
        "            target_dir = dog_dir\n",
        "        else:\n",
        "            continue  # Skip files without labels\n",
        "\n",
        "        # Move the file to the corresponding folder\n",
        "        shutil.move(file_path, target_dir)\n",
        "\n",
        "    # Delete the 'train' folder after moving all files\n",
        "    shutil.rmtree(source_dir)\n",
        "\n",
        "\n",
        "split_images(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Delete 80% of image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def delete_80_percent_of_files(cat_dir, dog_dir):\n",
        "    # Get the number of files in both directories\n",
        "    cat_files = os.listdir(cat_dir)\n",
        "    dog_files = os.listdir(dog_dir)\n",
        "\n",
        "    # Calculate 80% of the files in each directory\n",
        "    num_cat_files_to_delete = int(len(cat_files) * 0.8)\n",
        "    num_dog_files_to_delete = int(len(dog_files) * 0.8)\n",
        "\n",
        "    # Select files to delete in each directory\n",
        "    cat_files_to_delete = random.sample(cat_files, num_cat_files_to_delete)\n",
        "    dog_files_to_delete = random.sample(dog_files, num_dog_files_to_delete)\n",
        "\n",
        "    # Delete files that are in the lists\n",
        "    for file_name in cat_files:\n",
        "        if file_name in cat_files_to_delete:\n",
        "            file_path = os.path.join(cat_dir, file_name)\n",
        "            os.remove(file_path)\n",
        "\n",
        "    for file_name in dog_files:\n",
        "        if file_name in dog_files_to_delete:\n",
        "            file_path = os.path.join(dog_dir, file_name)\n",
        "            os.remove(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cat_dir = os.path.join(DatasetFolder, 'cat')\n",
        "dog_dir = os.path.join(DatasetFolder, 'dog')\n",
        "delete_80_percent_of_files(cat_dir, dog_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Split dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split dataset into train (70%), validation (10%) and test (20%) sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # gets classes labels\n",
        "    labels = os.listdir(my_data_dir)  # it should get only the folder names\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        # create train, test folders with classes labels sub-folder\n",
        "        for folder in ['train', 'validation', 'test']:\n",
        "            for label in labels:\n",
        "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
        "\n",
        "        for label in labels:\n",
        "\n",
        "            files = os.listdir(my_data_dir + '/' + label)\n",
        "            random.shuffle(files)\n",
        "\n",
        "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "            count = 1\n",
        "            for file_name in files:\n",
        "                if count <= train_set_files_qty:\n",
        "                    # move a given file to the train set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
        "\n",
        "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                    # move a given file to the validation set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "                else:\n",
        "                    # move given file to test set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
        "\n",
        "                count += 1\n",
        "\n",
        "            os.rmdir(my_data_dir + '/' + label)\n",
        "\n",
        "\n",
        "split_train_validation_test_images(my_data_dir=DatasetFolder,\n",
        "                                   train_set_ratio=0.7,\n",
        "                                   validation_set_ratio=0.1,\n",
        "                                   test_set_ratio=0.2\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Copy random dog and cat images to output folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def copy_random_images(number):\n",
        "\n",
        "    OutputFolder = 'outputs/sample_images'\n",
        "\n",
        "    cat_dir = os.path.join(DatasetFolder, 'validation/cat')\n",
        "    dog_dir = os.path.join(DatasetFolder, 'validation/dog')\n",
        "\n",
        "    sample_cat_dir = os.path.join(OutputFolder, 'cat')\n",
        "    sample_dog_dir = os.path.join(OutputFolder, 'dog')\n",
        "\n",
        "    # Create the sample directories if they don't exist\n",
        "    os.makedirs(sample_cat_dir, exist_ok=True)\n",
        "    os.makedirs(sample_dog_dir, exist_ok=True)\n",
        "\n",
        "    # Get a list of all cat and dog images\n",
        "    cat_images = os.listdir(cat_dir)\n",
        "    dog_images = os.listdir(dog_dir)\n",
        "\n",
        "    # Select a number of random images from each category\n",
        "    random_cat_images = random.sample(cat_images, number)\n",
        "    random_dog_images = random.sample(dog_images, number)\n",
        "\n",
        "    # Copy the selected images to the sample directories\n",
        "    for image in random_cat_images:\n",
        "        shutil.copy(os.path.join(cat_dir, image), sample_cat_dir)\n",
        "\n",
        "    for image in random_dog_images:\n",
        "        shutil.copy(os.path.join(dog_dir, image), sample_dog_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "copy_random_images(50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a zip file of the sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'outputs/sample_images.zip'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def create_zip_from_folder(folder_path, zip_filename=\"sample_images.zip\"):\n",
        "    zip_path = os.path.join(os.path.dirname(folder_path), zip_filename)\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
        "        for root, dirs, files in os.walk(folder_path):\n",
        "            for file in files:\n",
        "                file_path = os.path.join(root, file)\n",
        "                arcname = os.path.relpath(file_path, folder_path)\n",
        "                zipf.write(file_path, arcname)\n",
        "\n",
        "    return zip_path\n",
        "\n",
        "\n",
        "OutputFolder = 'outputs/sample_images'\n",
        "create_zip_from_folder(OutputFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dataset has been downloaded and images prepared for analysis. <br>\n",
        "Proceed to next notebook for Data visualization or Modelling and evaluation."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
