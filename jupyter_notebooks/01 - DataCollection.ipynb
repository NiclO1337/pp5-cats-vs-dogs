{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Data Collection**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Fetch images from Kaggle and split into train, test and validation folders\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* Kaggle JSON file - the authentication token.\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate Dataset: inputs/datasets/cats_vs_dogs_dataset\n",
        "\n",
        "## Additional Comments\n",
        "\n",
        "* Must delete unlabelled images from the Kaggle dataset as they can not be used for this project.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Install packages"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install requirements and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting joblib (from -r /workspace/pp5-cats-vs-dogs/requirements.txt (line 6))\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: joblib\n",
            "Successfully installed joblib-1.4.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirements installed.\n"
          ]
        }
      ],
      "source": [
        "%pip install -r /workspace/pp5-cats-vs-dogs/requirements.txt 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')\n",
        "import os\n",
        "import numpy\n",
        "import zipfile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "Change working directory to root project folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current folder: /workspace/pp5-cats-vs-dogs/jupyter_notebooks\n",
            "New folder: /workspace/pp5-cats-vs-dogs\n"
          ]
        }
      ],
      "source": [
        "current_dir = os.getcwd()\n",
        "print('Current folder: ' + current_dir)\n",
        "os.chdir(os.path.dirname(current_dir))\n",
        "current_dir = os.getcwd()\n",
        "print('New folder: ' + current_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Download dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Install Kaggle, configure the directory, and set permissions for the Kaggle authentication JSON.\n",
        "* Download the Kaggle dataset.\n",
        "* Unzip the file and delete the zip file and unlabeled images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install kaggle==1.5.12 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')\n",
        "\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = os.getcwd()\n",
        "! chmod 600 kaggle.json\n",
        "print('Directory configured and permissions set.')\n",
        "\n",
        "DestinationFolder = 'inputs/cats_vs_dogs_dataset'\n",
        "! kaggle competitions download -c dogs-vs-cats -p {DestinationFolder}\n",
        "\n",
        "print('Extracting files...')\n",
        "with zipfile.ZipFile(DestinationFolder + '/dogs-vs-cats.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)    \n",
        "\n",
        "with zipfile.ZipFile(DestinationFolder + '/train.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall(DestinationFolder)\n",
        "\n",
        "os.remove(DestinationFolder + '/dogs-vs-cats.zip')\n",
        "os.remove(DestinationFolder + '/test1.zip')\n",
        "os.remove(DestinationFolder + '/train.zip')\n",
        "os.remove(DestinationFolder + '/sampleSubmission.csv')\n",
        "print('Unused files deleted.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Data Preparation and cleaning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Install requirements and import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirements installed.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'inputs/cats_vs_dogs_dataset'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install -r /workspace/pp5-cats-vs-dogs/requirements.txt 2>/dev/null | grep -v 'Requirement already satisfied'\n",
        "print('Requirements installed.')\n",
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import joblib\n",
        "\n",
        "DatasetFolder = 'inputs/cats_vs_dogs_dataset'\n",
        "DatasetFolder"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check and remove non-image files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Folder: train - has image file 25000\n",
            "Folder: train - has non-image file 0\n"
          ]
        }
      ],
      "source": [
        "def remove_non_image_file(my_data_dir):\n",
        "    image_extension = ('.png', '.jpg', '.jpeg')\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    for folder in folders:\n",
        "        files = os.listdir(my_data_dir + '/' + folder)\n",
        "        # print(files)\n",
        "        i = []\n",
        "        j = []\n",
        "        for given_file in files:\n",
        "            if not given_file.lower().endswith(image_extension):\n",
        "                file_location = my_data_dir + '/' + folder + '/' + given_file\n",
        "                os.remove(file_location)  # remove non image file\n",
        "                i.append(1)\n",
        "            else:\n",
        "                j.append(1)\n",
        "                pass\n",
        "        print(f\"Folder: {folder} - has image file\", len(j))\n",
        "        print(f\"Folder: {folder} - has non-image file\", len(i))\n",
        "\n",
        "\n",
        "remove_non_image_file(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check how many images of cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total 'cat' images: 12500\n",
            "Total 'dog' images: 12500\n"
          ]
        }
      ],
      "source": [
        "def count_cat_dog_images(my_data_dir):\n",
        "    folders = os.listdir(my_data_dir)\n",
        "    \n",
        "    cat_count = 0  # Initialize counter for 'cat' images\n",
        "    dog_count = 0  # Initialize counter for 'dog' images\n",
        "    \n",
        "    for folder in folders:\n",
        "        files = os.listdir(os.path.join(my_data_dir, folder))\n",
        "        \n",
        "        for given_file in files:\n",
        "            file_location = os.path.join(my_data_dir, folder, given_file)\n",
        "            \n",
        "            # Check if the filename contains 'cat' or 'dog'\n",
        "            if 'cat' in given_file.lower():\n",
        "                cat_count += 1\n",
        "            elif 'dog' in given_file.lower():\n",
        "                dog_count += 1\n",
        "    \n",
        "    print(f\"Total 'cat' images: {cat_count}\")\n",
        "    print(f\"Total 'dog' images: {dog_count}\")\n",
        "\n",
        "\n",
        "count_cat_dog_images(my_data_dir=DatasetFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split into different folders for cats and dogs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_images(my_data_dir):\n",
        "    # Define the source and target directories\n",
        "    source_dir = os.path.join(my_data_dir, 'train')\n",
        "    cat_dir = os.path.join(my_data_dir, 'cat')\n",
        "    dog_dir = os.path.join(my_data_dir, 'dog')\n",
        "    \n",
        "    # Create 'cat' and 'dog' directories if they don't exist\n",
        "    for dir_name in [cat_dir, dog_dir]:\n",
        "        if not os.path.exists(dir_name):\n",
        "            os.makedirs(dir_name)\n",
        "    \n",
        "    # Iterate through all files in the 'train' folder\n",
        "    for file_name in os.listdir(source_dir):\n",
        "        file_path = os.path.join(source_dir, file_name)\n",
        "        \n",
        "        # Check if the filename contains 'cat' or 'dog'\n",
        "        if 'cat' in file_name.lower():\n",
        "            target_dir = cat_dir\n",
        "        elif 'dog' in file_name.lower():\n",
        "            target_dir = dog_dir\n",
        "        else:\n",
        "            continue  # Skip files without labels\n",
        "        \n",
        "        # Move the file to the corresponding folder\n",
        "        shutil.move(file_path, target_dir)\n",
        "    \n",
        "    # Delete the 'train' folder after moving all files\n",
        "    shutil.rmtree(source_dir)\n",
        "\n",
        "\n",
        "split_images(my_data_dir=DestinationFolder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Split dataset into train (70%), validation (10%) and test (20%) sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def split_train_validation_test_images(my_data_dir, train_set_ratio, validation_set_ratio, test_set_ratio):\n",
        "\n",
        "    if train_set_ratio + validation_set_ratio + test_set_ratio != 1.0:\n",
        "        print(\"train_set_ratio + validation_set_ratio + test_set_ratio should sum to 1.0\")\n",
        "        return\n",
        "\n",
        "    # gets classes labels\n",
        "    labels = os.listdir(my_data_dir)  # it should get only the folder names\n",
        "    if 'test' in labels:\n",
        "        pass\n",
        "    else:\n",
        "        # create train, test folders with classes labels sub-folder\n",
        "        for folder in ['train', 'validation', 'test']:\n",
        "            for label in labels:\n",
        "                os.makedirs(name=my_data_dir + '/' + folder + '/' + label)\n",
        "\n",
        "        for label in labels:\n",
        "\n",
        "            files = os.listdir(my_data_dir + '/' + label)\n",
        "            random.shuffle(files)\n",
        "\n",
        "            train_set_files_qty = int(len(files) * train_set_ratio)\n",
        "            validation_set_files_qty = int(len(files) * validation_set_ratio)\n",
        "\n",
        "            count = 1\n",
        "            for file_name in files:\n",
        "                if count <= train_set_files_qty:\n",
        "                    # move a given file to the train set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/train/' + label + '/' + file_name)\n",
        "\n",
        "                elif count <= (train_set_files_qty + validation_set_files_qty):\n",
        "                    # move a given file to the validation set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/validation/' + label + '/' + file_name)\n",
        "\n",
        "                else:\n",
        "                    # move given file to test set\n",
        "                    shutil.move(my_data_dir + '/' + label + '/' + file_name,\n",
        "                                my_data_dir + '/test/' + label + '/' + file_name)\n",
        "\n",
        "                count += 1\n",
        "\n",
        "            os.rmdir(my_data_dir + '/' + label)\n",
        "\n",
        "\n",
        "split_train_validation_test_images(my_data_dir=DatasetFolder,\n",
        "                                   train_set_ratio=0.7,\n",
        "                                   validation_set_ratio=0.1,\n",
        "                                   test_set_ratio=0.2\n",
        "                                   )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['cat', 'dog']"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "labels = os.listdir(DatasetFolder)\n",
        "\n",
        "labels\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "\n",
        "# Push files to Repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* In case you don't need to push files to Repo, you may replace this section with \"Conclusions and Next Steps\" and state your conclusions and next steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKlnIozA4eQO",
        "outputId": "fd09bc1f-adb1-4511-f6ce-492a6af570c0"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "try:\n",
        "  # create here your folder\n",
        "  # os.makedirs(name='')\n",
        "except Exception as e:\n",
        "  print(e)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions and Next Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
